---
ID: 3577
post_title: Deep Voice Report个人翻译
post_name: 'deep-voice-report%e4%b8%aa%e4%ba%ba%e7%bf%bb%e8%af%91'
author: 小奥
post_date: 2018-02-03 22:35:36
layout: post
link: >
  http://www.yushuai.me/2018/02/03/3577.html
published: true
tags:
  - 人工智能
  - 神经网络
categories:
  - Deep Learning
---
<span style="color: #FF0000;"><strong>个人翻译，水平有限，仅供参考。</strong></span><br/><p style="text-align: center;"><strong><span style="font-size:19px;line-height: 150%;font-family:宋体">摘要</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们展示了</span>Deep Voice<span style="font-family:宋体">，一个完全由深度神经网络构建的生产质量的文本到语音系统。</span> Deep Voice<span style="font-family:宋体">为真正的端到端神经语音合成奠定了基础。该系统包括五个主要构件：用于定位音素边界的分段模型，字形到音素转换模型，音素持续时间预测模型，基频预测模型和音频合成模型。对于分割模型，我们提出了一种使用连接主义时间分类（</span>CTC<span style="font-family:宋体">）丢失的深度神经网络进行音素边界检测的新方法。对于音频合成模型，我们实现了</span>WaveNet<span style="font-family:宋体">的一个变体，它需要更少的参数，并且训练速度比原来的要快。通过对每个组件使用神经网络，我们的系统比传统的文本托管系统更简单，更灵活，每个组件都需要费力的特征工程和广泛的领域专业知识。最后，我们展示了使用我们的系统进行推理可以比实时更快地进行，并且在</span>CPU<span style="font-family:宋体">和</span>GPU<span style="font-family:宋体">上描述优化的</span>WaveNet<span style="font-family:宋体">推理内核，在现有实现上实现高达</span>400<span style="font-family:宋体">倍的加速。</span></p><p><strong><span style="font-size:19px;line-height:150%">1.</span></strong><strong><span style="font-size:19px;line-height:150%;font-family:宋体">介绍</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">合成从文本到人类语音，俗称文本到语音（</span>TTS<span style="font-family:宋体">），是许多应用中，如语音设备、导航系统和盲人辅助视觉系统的必要成分。</span> <span style="font-family:宋体">从根本上说，它允许人机交互而不需要视觉界面。</span> <span style="font-family:宋体">现代</span>TTS<span style="font-family:宋体">系统基于复杂的多级处理流水线，每个处理流水线都可能依赖于手工设计的特征和启发式算法。</span> <span style="font-family:宋体">由于这种复杂性，开发新的</span>TTS<span style="font-family:宋体">系统可能是非常费力和困难的。</span></p><p style="text-indent:32px">Deep Voice<span style="font-family:宋体">的灵感来源于传统的文本到语音系统，它采用与之相同的结构，但用神经网络替换所有组件，并使用更简单的特点：首先我们将文本转换为音素，然后使用音频合成模型将语言特征转换为语音。</span> <span style="font-family:宋体">与之前的产品（使用人工设计的特征，如频谱包络，频谱参数，非周期性参数等）不同，我们唯一的特征是带有音调的音素，音素持续时间和基频（</span>F0<span style="font-family:宋体">）。</span> <span style="font-family: 宋体">这种功能的选择使我们的系统更容易适用于新的数据集、语音和其它领域，而无需任何手动数据注释或附加特征工程。我们通过重新训练整个算法来证明这一说法，而对全部新数据集没有任何超参数变化，这个全新数据集只包含音频和未对齐的文本转录，并产生相对高质量的语音。</span> <span style="font-family:宋体">在传统的</span>TTS<span style="font-family:宋体">系统中，这种调整需要几天到几周的调整，而</span>Deep Voice<span style="font-family:宋体">则只需要几个小时的手动操作和模型训练所需的时间。</span></p><p style="text-indent:32px"><span style="font-family:宋体">实时推断是高质量</span>TTS<span style="font-family:宋体">系统的要求</span>; <span style="font-family:宋体">没有它，系统对于对于</span>TTS<span style="font-family:宋体">的大多数应用程序是毫无用处的。之前的工作已经证明，</span>WaveNet<span style="font-family:宋体">能够产生接近于人类的语音。然而，由于模型的高频自回归特性，</span>WaveNet<span style="font-family:宋体">产生了了一个令人生畏的计算量，并且迄今为止我们还不知道这种模型是否可用于生产系统。</span> <span style="font-family:宋体">我们以肯定的方式回答了这个问题，并演示了高效的、比实时更快的</span>WaveNet<span style="font-family:宋体">推理内核，可以生成高质量的</span>16 kHz<span style="font-family:宋体">音频，并且比之前的</span>WaveNet<span style="font-family:宋体">推理实现实现了</span>400<span style="font-family:宋体">倍的加速。</span></p><p><strong><span style="font-size:19px;line-height:150%">2.</span></strong><strong><span style="font-size:19px;line-height:150%;font-family:宋体">相关工作</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">以前的研究使用神经网络作为</span>TTS<span style="font-family:宋体">系统中几个组件的替代品，这里面包括字形到音素转换模型、音素持续时间预测模型、基频预测模型和音频合成模型。然而，与</span>Deep Voice<span style="font-family:宋体">不同的是，这些系统都不能解决</span>TTS<span style="font-family:宋体">的全部问题，而且其中许多系统都使用专门为其领域开发的专用人工设计功能。</span></p><p style="text-indent:32px"><span style="font-family:宋体">最近，在参数音频合成方面有很多新的研究，如</span>WaveNet<span style="font-family:宋体">，</span>SampleRNN<span style="font-family:宋体">和</span>Char2Wav<span style="font-family:宋体">。虽然</span>WaveNet<span style="font-family:宋体">可用于有条件和无条件的音频生成，但</span>SampleRNN<span style="font-family:宋体">仅用于无条件音频生成，</span>Char2Wav<span style="font-family:宋体">使用基于注意力的音素持续时间模型和相当于</span>F0<span style="font-family:宋体">预测模型的</span>SampleRNN<span style="font-family:宋体">进行扩展，有效地为基于</span>SampleRNN<span style="font-family:宋体">的声码器提供本地调节信息。</span></p><p style="text-indent:32px">Deep Voice<span style="font-family:宋体">与这些系统在几个关键方面有所不同。</span> <span style="font-family:宋体">首先，</span>Deep Voice<span style="font-family:宋体">是完全独立的</span>; <span style="font-family:宋体">培训一个新的</span>Deep Voice<span style="font-family:宋体">系统不需要预先存在的</span>TTS<span style="font-family:宋体">系统，并且可以使用短音频剪辑和相应的文本转录本的数据集从头开始。</span> <span style="font-family:宋体">相比之下，再现上述系统中的任一个需要访问和理解预先存在的</span>TTS<span style="font-family:宋体">系统，因为它们使用来自另一</span>TTS<span style="font-family:宋体">系统的特征，无论是在训练还是推理时间。</span></p><p style="text-indent:32px"><span style="font-family:宋体">其次，</span>Deep Voice<span style="font-family:宋体">最大限度地减少了手工功能的使用</span>;<span style="font-family:宋体">它使用单字节编码字符来进行音素转换，单编码音素和应力，音素持续时间（以毫秒为单位），以及可以使用任何</span>F0<span style="font-family:宋体">估计算法从波形计算的归一化对数基频。所有这些都可以轻松地从音频和副本中轻松获得。相比之下，以前的作品使用的是更为复杂的特征表示，这使得在没有预先存在的</span>TTS<span style="font-family:宋体">系统的情况下再现系统是不可能的。</span> WaveNet<span style="font-family:宋体">使用</span>TTS<span style="font-family:宋体">系统中的几个特征，包括一个单词中音节的数量，短语中音节的位置，音素当前帧的位置，以及语音频谱的动态特征，如频谱和激励参数，以及他们的时间派生。</span> Char2Wav<span style="font-family:宋体">依靠</span>WORLD TTS<span style="font-family:宋体">系统的声码器特性来预先训练它们的对准模块，包括</span>F0<span style="font-family:宋体">，频谱包络和非周期参数。</span></p><p style="text-indent:32px"><span style="font-family:宋体">最后，我们着重于创建一个准产品级的系统，这需要我们的模型实时运行以进行推理。</span> Deep Voice<span style="font-family:宋体">可以在几分之一秒内合成音频，并在合成速度和音频质量之间提供可调节的折中。</span> <span style="font-family:宋体">相比之下，</span>WaveNet<span style="font-family:宋体">以前的结果需要几分钟的运行时间才能合成一秒钟的音频。</span> <span style="font-family: 宋体">我们不了解</span>SampleRNN<span style="font-family:宋体">的类似基准，但是原始出版物中描述的三层架构在推理过程中需要大约</span>4-5<span style="font-family:宋体">倍于我们最大的</span>WaveNet<span style="font-family:宋体">模型的计算量，因此实时运行该模型可能会遇到挑战。</span></p><p><strong><span style="font-size:19px;line-height:150%">3 TTS</span></strong><strong><span style="font-size:19px;line-height:150%;font-family:宋体">系统元素</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">如图</span>1<span style="font-family:宋体">所示，</span>TTS<span style="font-family:宋体">系统由五个主要组成部分组成：</span></p><p style="text-indent:32px"><span style="font-family:宋体">（</span>1<span style="font-family: 宋体">）字形到音素模型。它将书面文本（英文字符）转换成音素（使用诸如</span>ARPABET<span style="font-family:宋体">的音素字母表编码）。</span></p><p style="text-indent:32px"><span style="font-family:宋体">（</span>2<span style="font-family: 宋体">）分段模型。它在语音数据集中定位音素边界。</span> <span style="font-family:宋体">给定一个音频文件和一个音素的音素转录，该分割模型识别每个音素开始和结束在音频中的哪个位置。</span></p><p style="text-indent:32px"><span style="font-family:宋体">（</span>3<span style="font-family: 宋体">）音素持续时间模型。它是用来预测音素序列（发音）中每个音素的时间持续时间。</span></p><p style="text-indent:32px"><span style="font-family:宋体">（</span>4<span style="font-family: 宋体">）基频模型。它是用来预测音素是否有声：如果是，则模型预测音素持续时间内的基本频率（</span>F0<span style="font-family:宋体">）。</span></p><p style="text-indent:32px"><span style="font-family:宋体">（</span>5<span style="font-family: 宋体">）音频合成模型。它实现了字形到音素的输出，音素持续时间和基频预测模型，并以高采样率合成对应于期望文本的音频。</span></p><p style="text-align:center"><br/></p><p style="text-align:center"><span style="font-family:宋体">图</span>1 <span style="font-family: 宋体">描述（</span>a<span style="font-family:宋体">）训练程序和（</span>b<span style="font-family:宋体">）推理程序的系统图</span></p><p style="text-indent:32px"><span style="font-family:宋体">在图中，输入在左边，输出在右边。在我们的系统中，持续时间预测模型和</span>F0<span style="font-family:宋体">预测模型是通过一个联合损失训练的单个神经网络进行的。</span></p><p style="text-indent:32px"><span style="font-family:宋体">在推理过程中，通过字形到音素模型或音素字典输入文本以生成音素。接下来，音素被提供为音素持续时间模型和</span>F0<span style="font-family:宋体">预测模型的输入，以将持续时间分配给每个音素并生成</span>F0<span style="font-family:宋体">轮廓。最后，音素，音素持续时间和</span>F0<span style="font-family:宋体">被用作音频合成模型的本地调节输入特征，产生最终话语。</span></p><p style="text-indent:32px"><span style="font-family:宋体">与其他模型不同，在推断过程中不使用分割模型。而是用于用音素边界来注释训练语音数据。音素边界意味着持续时间，可用于训练音素持续时间模型。用音素和音素持续时间以及基本频率注释的音频被用来训练音频合成模型。</span></p><p style="text-indent:32px"><span style="font-family:宋体">在下面的章节中，我们将详细介绍所有构建块。</span></p><p><strong>3.1 </strong><strong><span style="font-family:宋体">字形到音素模型</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们的字素到音素模型是基于由（</span>Yao<span style="font-family:宋体">＆</span>Zweig<span style="font-family:宋体">，</span>2015<span style="font-family: 宋体">）开发的编码器解码器架构。然而，我们使用具有门控循环单元（</span>GRU<span style="font-family:宋体">）非线性和同样深度的单向</span>GRU<span style="font-family:宋体">解码器的多层双向编码器。每个解码器层的初始状态被初始化为对应的编码器前向层的最终隐藏状态。该架构是训练与教授强迫和解码是使用波束搜索进行的。</span> <span style="font-family:宋体">我们在编码器中使用</span>3<span style="font-family:宋体">个双向层，每个编码器有</span>1024<span style="font-family:宋体">个单元，解码器使用</span>3<span style="font-family:宋体">个相同尺寸的单向层，宽度为</span>5<span style="font-family:宋体">个候选者。在训练期间，我们在每个重复层之后以</span>0.95<span style="font-family:宋体">的概率使用丢失。</span></p><p style="text-indent:32px"><span style="font-family:宋体">对于训练，我们使用</span>Adam<span style="font-family:宋体">优化算法</span> <span style="font-family:宋体">，批量大小为</span>64<span style="font-family:宋体">，学习速率为</span> <span style="font-family:宋体">，并且每</span>1000<span style="font-family:宋体">次迭代施加</span>0.85<span style="font-family:宋体">的退火速率。</span></p><p><strong>3.2 </strong><strong><span style="font-family:宋体">分割模型</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们的分割模型被训练以输出给定话语和目标音素序列之间的对齐。这个任务类似于在语音识别中将语音与书写输出对齐的问题。在这个领域中，连接主义时态分类（</span>CTC<span style="font-family:宋体">）损失函数已经被证明集中在字符对齐以学习声音和文本之间的映射。我们采用最先进的语音识别系统来调整卷积递归神经网络架构的音素边界检测。</span></p><p style="text-indent:32px"><span style="font-family:宋体">用</span>CTC<span style="font-family:宋体">训练的生成音素序列的网络将为每个输出音素产生简短的峰值。虽然这足以大致将音素与音频对齐，但是不足以精确地检测精确的音素边界。为了克服这个问题，我们训练预测音素对的序列而不是单个音素。然后这个深度神经网络倾向于以接近两个音素之间的边界的时间步长输出音素对。</span></p><p style="text-indent:32px"><span style="font-family:宋体">为了说明我们的标签编码，考虑字符串“</span>Hello<span style="font-family:宋体">！”。要将其转换为音素对标签序列，需要先将发音转换为音素（使用发音词典，例如</span>CMUDict<span style="font-family:宋体">等），并将音素序列的两端用无声音音素填充以获得“</span>sil HH EH L OW sil<span style="font-family:宋体">”。</span> <span style="font-family:宋体">最后，构建连续的音素对并获得“</span>(sil, HH), (HH, EH), (EH, L), (L, OW), (OW, sil)<span style="font-family:宋体">”。</span></p><p style="text-indent:32px"><span style="font-family:宋体">通过以十毫秒的步幅计算</span>20<span style="font-family:宋体">个</span>Mel<span style="font-family:宋体">频率倒谱系数（</span>MFCC<span style="font-family:宋体">）来输入音频。</span> <span style="font-family:宋体">在输入层之上，有两个卷积层（时间和频率的二维卷积），三个双向循环</span>GRU<span style="font-family:宋体">层，最后是一个</span>softmax<span style="font-family:宋体">输出层。卷积层使用单位步长，高度</span>9<span style="font-family:宋体">（频率）和宽度</span>5<span style="font-family:宋体">（时间）的内核，并且循环层使用</span>512<span style="font-family:宋体">个</span>GRU<span style="font-family: 宋体">单元（对于每个方向）。在最后的卷积和重复图层之后应用</span>0.95<span style="font-family:宋体">的概率。为了计算音素对错误率（</span>PPER<span style="font-family:宋体">），我们使用波束搜索进行解码。为了解码音素边界，我们执行宽度为</span>50<span style="font-family:宋体">的束搜索，其中相邻音素对由至少一个音素重叠并且跟踪每个音素对的发音中的位置。</span></p><p style="text-indent:32px"><span style="font-family:宋体">训练中，我们使用</span>Adam<span style="font-family:宋体">优化算法</span> <span style="font-family:宋体">，批量大小为</span>128<span style="font-family:宋体">，学习速率为</span> <span style="font-family:宋体">，每</span>500<span style="font-family:宋体">次迭代应用</span>0.95<span style="font-family:宋体">的退火速率。</span></p><p><strong>3.3 </strong><strong><span style="font-family:宋体">音素持续时间和基频模型</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们使用单一架构来共同预测音素持续时间和基于时间的基频。模型的输入是一系列具有应力的音素，每个音素和压力被编码为一个热点矢量。该体系结构包括两个完全连接的层，每层</span>256<span style="font-family:宋体">个单元，随后是两个单向递归层，每个层具有</span>128<span style="font-family:宋体">个</span>GRU<span style="font-family:宋体">单元，最后是完全连接的输出层。在初始完全连接图层和最后一个重复图层之后，应用概率为</span>0.8<span style="font-family:宋体">的丢弃率。</span></p><p style="text-indent:32px"><span style="font-family:宋体">最后一层为每个输入音素产生三个估计值：音素持续时间，音素发出的概率（即具有基本频率）和</span>20<span style="font-family:宋体">个时间相关的</span>F0<span style="font-family:宋体">值，它们在预测的持续时间内均匀采样。</span></p><p style="text-indent:32px"><span style="font-family:宋体">该模型通过最小化联合损失来优化，所述联合损失结合了音素持续时间误差，基本频率误差，音素被发声概率的负对数似然性和与</span>F0<span style="font-family:宋体">相对于时间的绝对变化成比例的惩罚项以施加平滑。</span></p><p style="text-indent:32px"><span style="font-family:宋体">训练中，我们使用</span>Adam<span style="font-family:宋体">优化算法</span> <span style="font-family:宋体">，批量大小为</span>128<span style="font-family:宋体">，学习速率为</span> <span style="font-family:宋体">，每</span>400<span style="font-family:宋体">次迭代应用</span>0.9886<span style="font-family:宋体">的退火速率。</span></p><p><strong>3.4 </strong><strong><span style="font-family:宋体">语音合成模块</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们的音频合成模型是</span>WaveNet<span style="font-family:宋体">的一个变种。</span> WaveNet<span style="font-family:宋体">由一个调节网络和一个自动回归网络组成，该网络可以将语言特征上离散采样得到的样本点</span> <span style="font-family:宋体">产生期望的频率</span> <span style="font-family:宋体">。我们改变层数</span>l<span style="font-family:宋体">，残余频道的数量</span>r<span style="font-family:宋体">（每层的隐藏状态的维度）和跳过通道的数量</span>s<span style="font-family:宋体">（在输出层之前投影层输出的尺寸）。</span></p><p style="text-indent:32px">WaveNet<span style="font-family:宋体">由一个上采样和调节网络组成，其次是</span>l 2<span style="font-family:宋体">×</span>1<span style="font-family: 宋体">卷积层、带有</span>r<span style="font-family:宋体">个剩余输出通道和双曲正切门控非线性。我们用</span> <span style="font-family:宋体">和</span> <span style="font-family:宋体">将卷积分解为每个时间步长的两个矩阵乘法。这些层与剩余连接相连接。每一层的隐藏状态连接到一个</span>lr<span style="font-family:宋体">个矢量，并投影到跳过</span> <span style="font-family:宋体">通道，然后是两层</span>1<span style="font-family:宋体">×</span>1<span style="font-family:宋体">的卷积（权重为</span> <span style="font-family:宋体">和</span> <span style="font-family:宋体">）。</span></p><p style="text-indent:32px">WaveNet<span style="font-family:宋体">使用转置卷积进行上采样和调节。我们发现，如果我们首先用一叠双向准</span>RNN<span style="font-family:宋体">（</span>QRNN<span style="font-family: 宋体">）层对输入进行编码，然后通过重复执行到所需频率的上采样，我们的模型执行得更好，训练速度更快，并且需要更少的参数。</span></p><p style="text-indent:32px"><span style="font-family:宋体">我们的取得很高质量的最终模型使用</span>l=40<span style="font-family:宋体">层，</span>r=64<span style="font-family:宋体">个残留信道，</span>s=256<span style="font-family:宋体">个跳过通道。训练中，我们使用</span>Adam<span style="font-family:宋体">优化算法</span> <span style="font-family:宋体">，批量大小为</span>8<span style="font-family:宋体">，学习速率为</span> <span style="font-family:宋体">，每</span>1000<span style="font-family:宋体">次迭代应用</span>0.9886<span style="font-family:宋体">的退火速率。</span></p><p><strong><span style="font-size:19px;line-height:150%">4.</span></strong><strong><span style="font-size:19px;line-height:150%;font-family:宋体">测试结果</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们在一个内部的英语语音数据库上训练我们的模型，这个数据库包含大约</span>20<span style="font-family:宋体">个小时的语音数据，分成</span>13079<span style="font-family:宋体">个语音。另外，我们为我们在</span>Blizzard 2013<span style="font-family:宋体">数据的子集上训练的模型展示了音频合成结果。这两个数据集都是由专业的女性演讲者讲的。</span></p><p style="text-indent:32px"><span style="font-family:宋体">另外，我们所有的模型都是使用</span>TensorFlow<span style="font-family:宋体">框架实现的。</span></p><p><strong>4.1 </strong><strong><span style="font-family:宋体">分割模块结果</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们使用</span>8<span style="font-family:宋体">颗</span>TitanX Maxwell GPU<span style="font-family:宋体">进行训练，在</span>GPU<span style="font-family:宋体">中平均分配每个批次，并使用</span>ring all-reduce<span style="font-family:宋体">来计算在不同</span>GPU<span style="font-family:宋体">上计算的平均梯度，每次迭代大约需要</span>1300<span style="font-family:宋体">毫秒。在大约</span>14,000<span style="font-family:宋体">次迭代之后，该模型收敛到</span>7<span style="font-family:宋体">％的音素对错误率。我们还发现，音素边界不必是精确的，随机移动音素边界</span>10-30<span style="font-family:宋体">毫秒没有任何区别的音频质量，所以怀疑音频质量对错误率未超过某一点并不敏感。</span></p><p><strong>4.2 </strong><strong><span style="font-family:宋体">字形到音素模块的结果</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们对从</span>CMUDict<span style="font-family:宋体">获得的数据训练一个字形到音素的模型。我们删除所有不以字母开头，包含数字或者有多个发音的单词，从原始的</span>133854<span style="font-family:宋体">个字形音素序列对中留下</span>124978<span style="font-family:宋体">个单词。</span></p><p style="text-indent:32px"><span style="font-family:宋体">我们在单个</span>TitanX Maxwell GPU<span style="font-family:宋体">上进行训练，每次迭代大约需要</span>150<span style="font-family:宋体">毫秒。经过大约</span>20000<span style="font-family:宋体">次迭代后，模型收敛到</span>5.8<span style="font-family:宋体">％的音素错误率和</span>28.7<span style="font-family:宋体">％的字错误率，这与之前的报告结果一致。与以前的工作不同，我们在解码期间不使用语言模型，</span> <span style="font-family:宋体">包括在我们的数据集中有多个发音的单词。</span></p><p><strong>4.3 </strong><strong><span style="font-family:宋体">音素持续时间和基本频率模块结果</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们在单个</span>TitanX Maxwell GPU<span style="font-family:宋体">上进行训练，每次迭代大约需要</span>120<span style="font-family:宋体">毫秒。经过大约</span>20000<span style="font-family:宋体">次迭代后，模型收敛到</span>38<span style="font-family:宋体">毫秒（对于音素持续时间）和</span>29.4Hz<span style="font-family:宋体">（对于基频）的平均绝对误差。</span></p><p><strong>4.4 </strong><strong><span style="font-family:宋体">语音合成模块结果</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">我们将音频数据集中的话语分成一个块，每个块有四分之一的上下文，在开始时用四分之一秒的静音填充每个话语。我们过滤掉主要是沉默的块，最后总共有</span>74348<span style="font-family:宋体">个块。</span></p><p style="text-indent:32px"><span style="font-family:宋体">们训练了不同深度的模型，包括剩余层堆叠中的</span>10,20,30<span style="font-family:宋体">和</span>40<span style="font-family:宋体">层。我们发现</span>20<span style="font-family:宋体">层以下的模型会导致音质不佳。</span>20<span style="font-family:宋体">层，</span>30<span style="font-family: 宋体">层和</span>40<span style="font-family:宋体">层模型都产生高质量的可识别语音，但是</span>40<span style="font-family:宋体">层模型比</span>20<span style="font-family:宋体">层模型具有更低的噪声，可以用高品质的耳机进行检测。</span></p><p style="text-indent:32px"><span style="font-family:宋体">以前的工作已经强调了在确定模型质量时接受场尺寸的重要性。事实上，</span>20<span style="font-family:宋体">层模型只有</span>40<span style="font-family:宋体">层模型的一半。然而，当以</span>48kHz<span style="font-family:宋体">运行时，具有</span>40<span style="font-family:宋体">层的模型只有</span>83<span style="font-family:宋体">毫秒的接收场，但仍然产生高质量的音频。这表明</span>20<span style="font-family:宋体">层模型的接受场是足够的，我们推测音频质量的差异是由于接受场大小以外的其他因素。</span></p><p style="text-indent:32px"><span style="font-family:宋体">我们在</span>8<span style="font-family:宋体">颗</span>TitanX Maxwell GPU<span style="font-family:宋体">上训练，每个</span>GPU<span style="font-family:宋体">有一个块，使用</span>ring allreduce<span style="font-family:宋体">来平均在不同</span>GPU<span style="font-family:宋体">上计算出的梯度。每次迭代大约需要</span>450<span style="font-family:宋体">毫秒。我们的模型在大约</span>300000<span style="font-family:宋体">次迭代之后收敛。我们发现单个</span>1.25s<span style="font-family:宋体">块足以使</span>GPU<span style="font-family:宋体">上的计算饱和，并且批处理不会提高训练效率。</span></p><p style="text-indent:32px"><span style="font-family:宋体">与高维生成模型一样，模型损失与个体样本的感知质量有些不相关。虽然具有非常高的损耗声音模型明显嘈杂，模型优化低于一定的阈值没有损失指示其质量。另外，模型架构的变化（如深度和输出频率）可能会对模型损失产生重大影响，同时对音频质量的影响很小。</span></p><p style="text-indent:32px"><span style="font-family:宋体">为了评估我们</span>TTS<span style="font-family:宋体">管道各个阶段的感知质量，我们使用</span>CrowdMOS<span style="font-family:宋体">工具包和方法，从</span>Mechanical Turk<span style="font-family:宋体">获得了众多的平均评分（</span>MOS<span style="font-family:宋体">）评级。为了分离音频预处理效果、</span>WaveNet<span style="font-family:宋体">模型质量、音素持续时间和基频模型质量，我们给出了各种话语类型的</span>MOS<span style="font-family:宋体">分数，包括</span>WaveNet<span style="font-family:宋体">输入（持续时间和</span>F0<span style="font-family:宋体">），从真实音频中提取而不是由其他模型合成的综合结果，结果如表</span>1<span style="font-family:宋体">所示。我们有意将绝对真实样本包含在批评者评估的每批样本中，以突出人类言语中的三角洲，并允许评估者区分模型之间的细微差别</span>; <span style="font-family:宋体">这种方法的不足之处在于，由此产生的</span>MOS<span style="font-family:宋体">分数将显着低于仅以合成音频样本呈现的评分者。</span></p><p style="text-align:center"><span style="font-family:宋体">表</span>1 <span style="font-family: 宋体">平均意见评分</span></p><table width="99"><tbody><tr class="firstRow"><td style="border: 1px solid windowtext; padding: 0px 7px;" width="42" valign="top"><p style="text-align:center"><span style="font-family:宋体">类型</span></p></td><td style="border-color: windowtext windowtext windowtext currentcolor; border-style: solid solid solid none; border-width: 1px 1px 1px medium; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center"><span style="font-family:宋体">模型大小</span></p></td><td style="border-color: windowtext windowtext windowtext currentcolor; border-style: solid solid solid none; border-width: 1px 1px 1px medium; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">MOS<span style="font-family:宋体">±</span>CI</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">绝对真实声音（</span>48kHz<span style="font-family:宋体">）</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center"><span style="font-family:宋体">无</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">4.75<span style="font-family:宋体">±</span>0.12</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">绝对真实声音</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center"><span style="font-family:宋体">无</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">4.45<span style="font-family:宋体">±</span>0.16</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">绝对真实声音（扩展）</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center"><span style="font-family:宋体">无</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">4.34<span style="font-family:宋体">±</span>0.18</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">合成声音</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center">l=40, &nbsp; r=64, s=256</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">3.94<span style="font-family:宋体">±</span>0.26</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">合成声音（</span>48kHz<span style="font-family:宋体">）</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center">l=40, &nbsp; r=64, s=256</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">3.84<span style="font-family:宋体">±</span>0.24</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">合成声音</span>(<span style="font-family:宋体">合成的</span>F0)</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center">l=40, &nbsp; r=64, s=256</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">2.76<span style="font-family:宋体">±</span>0.31</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">合成声音（持续时间和</span>F0<span style="font-family:宋体">）</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center">l=40, &nbsp; r=64, s=256</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">2.00<span style="font-family:宋体">±</span>0.23</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">合成声音（</span>2<span style="font-family:宋体">倍实时推理）</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center">l=20 &nbsp; r=32, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">2.74<span style="font-family:宋体">±</span>0.32</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="42" valign="top"><p style="text-align:left"><span style="font-family:   宋体">合成声音（</span>1<span style="font-family:宋体">倍实时推理）</span></p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="34" valign="top"><p style="text-align:center">l=20 &nbsp; r=64, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p style="text-align:center">3.35<span style="font-family:宋体">±</span>0.31</p></td></tr></tbody></table><p style="text-indent:32px"><span style="font-family:宋体">首先，当简单地将音频流从</span>48kHz<span style="font-family:宋体">下采样到</span>16kHz<span style="font-family:宋体">时，我们发现</span>MOS<span style="font-family:宋体">的显着下降，尤其是与μ律压缩和量化相结合，这可能是因为</span>48kHz<span style="font-family:宋体">采样被呈现给评估者作为基准一个</span>5<span style="font-family:宋体">分和一个低质量噪声合成结果被表示为</span>1<span style="font-family:宋体">。当将绝对真实持续时间和</span>F0<span style="font-family:宋体">一起使用时，我们的模型得分很高，我们的模型的</span>95<span style="font-family:宋体">％置信区间与地面真实样本的相交。然而，使用合成频率减小了</span>MOS<span style="font-family:宋体">，进一步合成持续时间显着减小了它。我们得出结论：自然</span>TTS<span style="font-family:宋体">发展的主要障碍在于持续时间和基频预测，而我们的系统在这方面并没有有意义的进展。最后，我们的最佳模型运行速度略低于实时（见表</span>2<span style="font-family:宋体">），所以我们证实，合成质量可以通过获得比实时快</span>1<span style="font-family:宋体">至</span>2<span style="font-family:宋体">倍的模型的分数来调制模型大小进行快速推理。</span></p><p style="text-indent:32px"><span style="font-family:宋体">我们还测试了</span>WaveNet<span style="font-family:宋体">模型，这些模型是从原始的</span>WaveNet<span style="font-family:宋体">出版物的全套特征进行训练的，但是发现在这些模型和模型之间没有感觉上的差异。</span></p><p style="text-align:center"><span style="font-family:宋体">表</span>2 <span style="font-family: 宋体">针对</span>float32<span style="font-family:宋体">和</span>int16<span style="font-family:宋体">中不同模型的</span>CPU<span style="font-family:宋体">和</span>GPU<span style="font-family: 宋体">推理内核基准</span></p><table width="99"><tbody><tr class="firstRow"><td style="border: 1px solid windowtext; padding: 0px 7px;" width="29" valign="top"><p><span style="font-family:宋体">模型</span></p></td><td style="border-color: windowtext windowtext windowtext currentcolor; border-style: solid solid solid none; border-width: 1px 1px 1px medium; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="23" valign="top"><p><span style="font-family:宋体">平台</span></p></td><td style="border-color: windowtext windowtext windowtext currentcolor; border-style: solid solid solid none; border-width: 1px 1px 1px medium; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="17" valign="top"><p><span style="font-family:宋体">数据类型</span></p></td><td style="border-color: windowtext windowtext windowtext currentcolor; border-style: solid solid solid none; border-width: 1px 1px 1px medium; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="13" valign="top"><p><span style="font-family:宋体">线程数</span></p></td><td style="border-color: windowtext windowtext windowtext currentcolor; border-style: solid solid solid none; border-width: 1px 1px 1px medium; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="16" valign="top"><p><span style="font-family:宋体">实时加速</span></p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=20, r=32, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>CPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>6</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>2.7</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=20, r=32, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>CPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>2</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>2.05</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=20, r=64, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>CPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>int16</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>2</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>1.2</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=20, r=64, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>CPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>6</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>1.11</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=20, r=64, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>CPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>2</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>0.79</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=40, r=64, s=256</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>CPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>int16</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>2</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>0.67</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=40, r=64, s=256</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>CPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>6</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>0.61</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=40, r=64, s=256</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>CPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>2</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>0.35</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=20, r=32, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>GPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>N/A</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>0.39</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=20, r=64, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>GPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>N/A</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>0.29</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=40, r=32, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>GPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>N/A</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>0.23</p></td></tr><tr><td style="border-color: currentcolor windowtext windowtext; border-style: none solid solid; border-width: medium 1px 1px; border-image: none 100% / 1 / 0 stretch; -moz-border-top-colors: none; -moz-border-left-colors: none; -moz-border-bottom-colors: none; -moz-border-right-colors: none; padding: 0px 7px;" width="29" valign="top"><p>l=40, r=64, s=128</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="23" valign="top"><p>GPU</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="17" valign="top"><p>float32</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="13" valign="top"><p>N/A</p></td><td style="border-color: currentcolor windowtext windowtext currentcolor; border-style: none solid solid none; border-width: medium 1px 1px medium; padding: 0px 7px;" width="16" valign="top"><p>0.17</p></td></tr></tbody></table><p><strong>5 </strong><strong><span style="font-family:宋体">结论</span></strong></p><p style="text-indent:32px"><span style="font-family:宋体">在这项工作中，我们通过建立一个完全的神经系统来证明当前的深度学习方法对于高质量的文本到语音引擎的所有组件是可行的。我们将推理优化为比实时更快的速度，表明这些技术可以用于以流媒体方式实时生成音频。</span> <span style="font-family:宋体">我们的系统可以在没有任何人员参与的情况下进行训练，大大简化了创建</span>TTS<span style="font-family:宋体">系统的过程。</span></p><p style="text-indent:32px"><span style="font-family:宋体">我们的工作打开了许多新的可能的探索方向。</span> <span style="font-family:宋体">通过仔细优化，</span>GPU<span style="font-family:宋体">上的模型量化和</span>CPU<span style="font-family:宋体">上的</span>int8<span style="font-family: 宋体">量化，以及其他体系结构的实验，可以进一步提高推理性能。</span> <span style="font-family:宋体">另一个自然的方向是消除阶段之间的分离，并将分割，持续时间预测和基频预测模型直接合并到音频合成模型中，从而将问题转化为完整的序列到序列模型，从而创建单个端到端模型，</span> <span style="font-family:宋体">结束了可训练的</span>TTS<span style="font-family:宋体">系统，使我们能够在没有中间监督的情况下训练整个系统。</span> <span style="font-family: 宋体">代替融合模型，通过更大的训练数据集或生成建模技术来改进持续时间和频率模型可能会对语音自然度产生影响。</span></p>