---
ID: 3582
post_title: >
  吴恩达深度学习课程DeepLearning.ai笔记（2-1）
post_name: '%e5%90%b4%e6%81%a9%e8%be%be%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e8%af%be%e7%a8%8bdeeplearning-ai%e7%ac%94%e8%ae%b0%ef%bc%882-1%ef%bc%89'
author: 小奥
post_date: 2018-02-06 00:20:41
layout: post
link: >
  http://www.yushuai.me/2018/02/06/3582.html
published: true
tags:
  - 吴恩达
  - 深度学习
categories:
  - Deep Learning
---
<h1 style="font-size: 32px; font-weight: bold; border-bottom: 2px solid rgb(204, 204, 204); padding: 0px 4px 0px 0px; text-align: left; margin: 0px 0px 10px;"><span style=";color:#2C3033">改善深层神经网络：超参数调试、正则化以及优化</span></h1><p><br/></p><h3 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:30px;background:white"><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">第一节 训练、验证、测试集</span></h3><p><span style=";color:#2C3033">对于数据，我们可以划分为以下3类：</span></p><p class="MsoListParagraph" style="margin-left:48px"><span style=";color:#2C3033">（1）</span><span style=";color:#2C3033">训练集（Train Set），顾名思义，用来训练模型的数据。</span></p><p class="MsoListParagraph" style="margin-left:48px"><span style=";color:#2C3033">（2）</span><span style=";color:#2C3033">交叉检验集(hold-out cross validation set)，选出最好的模型。</span></p><p class="MsoListParagraph" style="margin-left:48px"><span style=";color:#2C3033">（3）</span><span style=";color:#2C3033">测试集，最后利用测试集对模型进行测试，获取模型运行的无偏估计。</span></p><p style="text-indent:28px"><span style=";color:#2C3033">一般情况下，要求交叉检验集和测试集越小越好（当然在数据较小的时候可以采用7/2/1的比例）。</span></p><p style="text-indent:28px"><span style=";color:#2C3033">验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大能够验证大约2-10种算法哪种更好就足够了，不需要使用20%的数据作为验证集。如百万数据中抽取1万的数据作为验证集就可以了。</span></p><p style="text-indent:28px"><span style=";color:#2C3033">测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中1000条数据足以评估单个模型的效果。</span></p><p><strong><span style=";color:#2C3033">注意：</span></strong></p><p><span style=";color:#2C3033">（1）建议验证集要和训练集来自于同一个分布，可以使得机器学习算法变得更快；</span></p><p><span style=";color:#2C3033">（2）如果不需要用无偏估计来评估模型的性能，则可以不需要测试集。</span></p><h3 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:30px;background:white"><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">第二节 偏差与方差</span></h3><p style="text-align: center;"><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"><img src="/wp-content/uploads/image/20180206/1517847540761604.jpg" title="1517847540761604.jpg" alt="1517847540761604.jpg" width="596" height="157"/></span></p><p><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"><br/></span></p><p style="text-indent:28px"><span style=";color:#2C3033">高偏差代表着拟合效果太差，需要加深网络层数。</span></p><p style="text-indent:28px"><span style=";color:#2C3033">高方差代表着过拟合（overfitting），可以采取增加数据量（成本太高）或者采取正则化。关于正则化后面会说。</span></p><p style="text-indent:28px"><span style=";color:#2C3033">关于训练情况是高偏差还是高方差，可以通过以下几个例子来说明：</span></p><p style="text-align:center"><span style=";color:#2C3033">表2.1 训练举例</span></p><table><tbody><tr class="firstRow"><td width="104" valign="top" style="border-width: 1px; border-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">Train set error</span></p></td><td width="118" valign="top" style="border-top-width: 1px; border-right-width: 1px; border-bottom-width: 1px; border-top-color: windowtext; border-right-color: windowtext; border-bottom-color: windowtext; border-left: none; padding: 0px 7px;"><p><span style=";color:#2C3033">1%</span></p></td><td width="111" valign="top" style="border-top-width: 1px; border-right-width: 1px; border-bottom-width: 1px; border-top-color: windowtext; border-right-color: windowtext; border-bottom-color: windowtext; border-left: none; padding: 0px 7px;"><p><span style=";color:#2C3033">15%</span></p></td><td width="111" valign="top" style="border-top-width: 1px; border-right-width: 1px; border-bottom-width: 1px; border-top-color: windowtext; border-right-color: windowtext; border-bottom-color: windowtext; border-left: none; padding: 0px 7px;"><p><span style=";color:#2C3033">15%</span></p></td><td width="111" valign="top" style="border-top-width: 1px; border-right-width: 1px; border-bottom-width: 1px; border-top-color: windowtext; border-right-color: windowtext; border-bottom-color: windowtext; border-left: none; padding: 0px 7px;"><p><span style=";color:#2C3033">0.5%</span></p></td></tr><tr><td width="104" valign="top" style="border-right-width: 1px; border-bottom-width: 1px; border-left-width: 1px; border-right-color: windowtext; border-bottom-color: windowtext; border-left-color: windowtext; border-top: none; padding: 0px 7px;"><p><span style=";color:#2C3033">Dev set error</span></p></td><td width="118" valign="top" style="border-top: none; border-left: none; border-bottom-width: 1px; border-bottom-color: windowtext; border-right-width: 1px; border-right-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">11%</span></p></td><td width="111" valign="top" style="border-top: none; border-left: none; border-bottom-width: 1px; border-bottom-color: windowtext; border-right-width: 1px; border-right-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">16%</span></p></td><td width="111" valign="top" style="border-top: none; border-left: none; border-bottom-width: 1px; border-bottom-color: windowtext; border-right-width: 1px; border-right-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">30%</span></p></td><td width="111" valign="top" style="border-top: none; border-left: none; border-bottom-width: 1px; border-bottom-color: windowtext; border-right-width: 1px; border-right-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">1%</span></p></td></tr><tr><td width="104" valign="top" style="border-right-width: 1px; border-bottom-width: 1px; border-left-width: 1px; border-right-color: windowtext; border-bottom-color: windowtext; border-left-color: windowtext; border-top: none; padding: 0px 7px;"><p><span style=";color:#2C3033">类型</span></p></td><td width="118" valign="top" style="border-top: none; border-left: none; border-bottom-width: 1px; border-bottom-color: windowtext; border-right-width: 1px; border-right-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">高方差（过拟合）</span></p></td><td width="111" valign="top" style="border-top: none; border-left: none; border-bottom-width: 1px; border-bottom-color: windowtext; border-right-width: 1px; border-right-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">高偏差（欠拟合）</span></p></td><td width="111" valign="top" style="border-top: none; border-left: none; border-bottom-width: 1px; border-bottom-color: windowtext; border-right-width: 1px; border-right-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">高偏差（欠拟合）</span></p></td><td width="111" valign="top" style="border-top: none; border-left: none; border-bottom-width: 1px; border-bottom-color: windowtext; border-right-width: 1px; border-right-color: windowtext; padding: 0px 7px;"><p><span style=";color:#2C3033">低偏差</span></p><p><span style=";color:#2C3033">低方差</span></p></td></tr></tbody></table><h3 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:30px;background:white"><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">第三节 机器学习的基本方法（解决高偏差和高方差问题）</span></h3><p><span style=";color:#2C3033">（1）存在高偏差：</span></p><p class="MsoListParagraph" style="margin-left:48px;text-indent:0"><span style=";color:#2C3033">-</span><span style=";color:#2C3033">增加网络结构，例如增加隐藏层数目等</span></p><p class="MsoListParagraph" style="margin-left:48px;text-indent:0"><span style=";color:#2C3033">-</span><span style=";color:#2C3033">训练更长时间</span></p><p class="MsoListParagraph" style="margin-left:48px;text-indent:0"><span style=";color:#2C3033">-</span><span style=";color:#2C3033">寻找更加合适的网络结构</span></p><p><span style=";color:#2C3033">（2）存在高方差：</span></p><p><span style=";color:#2C3033">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;-</span><span style=";color:#2C3033">获取更多数据</span></p><p><span style=";color:#2C3033">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -</span><span style=";color:#2C3033">正则化</span></p><p><span style=";color:#2C3033">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -</span><span style=";color:#2C3033">寻找合适的网络</span></p><p><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"></span></p><h3 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:30px;background:white"><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">第四节 正则化</span></h3><p><span style="font-size:16px;color:#2C3033">4.1</span> <span style="font-size:16px">关于正则化（</span><span style="font-size:16px;color:#2C3033">regularization</span><span style="font-size:16px;color:#2C3033">）</span></p><p><span style=";color:#2C3033">逻辑回归：</span></p><p><span style=";color:#2C3033">加入正则化项的代价函数： </span></p><p style="text-align: center;"><span style=";color:#2C3033"><img src="/wp-content/uploads/image/20180206/1517847701123216.png" title="1517847701123216.png" alt="1517847701123216.png" width="544" height="195"/></span></p><p><br/></p><p><strong><span style=";color:red">注意：lambda在python中属于保留字，所以在编程的时候，用“lambd”代表这里的正则化因子λ。</span></strong></p><p>加入正则化项的代价函数：</p><p style="text-align: center;"><img src="/wp-content/uploads/image/20180206/1517848507473069.jpg" title="1517848507473069.jpg" alt="1517848507473069.jpg" width="470" height="79"/></p><p>后面||W||<sub>F</sub><sup>2</sup>为W的F范数，W的维度为(n<sup>[l]</sup>,n<sup>[l-1]</sup>)</p><p style="text-indent:28px"><span style=";color:#2C3033">正则化的格式：</span></p><p><span style=";color:#2C3033">（1）梯度变为：</span></p><p class="MsoListParagraph" style="margin-left:48px;text-align: center;text-indent:0"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">d</span><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">W</span></span><sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></span></sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup><span style=";font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">l</span></sup><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></sup></span></span></span></span><span style="box-sizing: border-box">=</span><span style="box-sizing: border-box">(</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">f</span><span style="box-sizing: border-box">o</span><span style="box-sizing: border-box">r</span><span style="box-sizing: border-box">m</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">_</span><span style="font-size: 20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">b</span><span style="box-sizing: border-box">a</span><span style="box-sizing: border-box">c</span><span style="box-sizing: border-box">k</span><span style="box-sizing: border-box">p</span><span style="box-sizing: border-box">r</span><span style="box-sizing: border-box">o</span><span style="box-sizing: border-box">p</span><span style="font-size: 20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">)</span><span style="box-sizing: border-box">+</span><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">(</span></span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">λ</span><span style="box-sizing: border-box;clip:rect(1.683em 1000em 2.442em -0.485em)"><span style="box-sizing: border-box">/m</span></span></span></span></span></span><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">)W</span></span><sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></span></sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup><span style=";font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">l</span></sup><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></sup></span></span></span></span></p><p>（2）梯度更新变为：</p><p style="text-align:center"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">W</span><sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup><span style=";font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">l</span></sup><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></sup></span><span style="box-sizing: border-box">:<span style="box-sizing: border-box;border-color:transparent !important">=</span></span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">W</span></span><sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></span></sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup>l</sup><sup><span style="font-family: MathJax_Main, serif">]</span></sup></span></span></span></span><span style="box-sizing: border-box">−</span></span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">α</span><span style="box-sizing: border-box">d</span><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">W</span></span><sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></span></sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup><span style=";font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">l</span></sup><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></sup></span></span></span></span></p><p><span style=";color:#2C3033">（3）代入得到：</span></p><p style="text-align:center"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">W</span><sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup><span style=";font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">l</span></sup><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></sup></span><span style="box-sizing: border-box;text-align: start">=</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">(</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;text-align: start">1</span></span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;text-align: start">−</span></span><span style="box-sizing: border-box;border-color:transparent !important"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;text-align: start"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box"><span style="box-sizing: border-box">α</span><span style="box-sizing: border-box;border-color: transparent !important">λ</span></span></span><span style="box-sizing: border-box;clip:rect(1.683em 1000em 2.442em -0.485em)"><span style="box-sizing: border-box">m</span></span></span></span></span></span><span style="box-sizing: border-box;text-align: start">)</span></span><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box;text-align: start"><span style="box-sizing: border-box">W</span></span><sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></span></sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup>l</sup><sup><span style="font-family: MathJax_Main, serif">]</span></sup></span></span></span></span><span style="box-sizing: border-box;text-align: start">−</span></span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;text-align: start">α</span></span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;text-align: start">(</span></span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;text-align: start">f</span><span style="box-sizing: border-box;text-align: start">o</span><span style="box-sizing: border-box;text-align: start">r</span><span style="box-sizing: border-box;text-align: start">m</span></span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;text-align: start">_</span></span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;text-align: start">b</span><span style="box-sizing: border-box;text-align: start">a</span><span style="box-sizing: border-box;text-align: start">c</span><span style="box-sizing: border-box;text-align: start">k</span><span style="box-sizing: border-box;text-align: start">p</span><span style="box-sizing: border-box;text-align: start">r</span><span style="box-sizing: border-box;text-align: start">o</span><span style="box-sizing: border-box;text-align: start">p</span></span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;text-align: start">)</span></span></p><p style="text-indent:28px"><span style=";color:#2C3033">其中，(1</span><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:#2C3033">−</span><span style=";color:#2C3033">αλ</span><span style=";color:#2C3033">m)</span><span style=";color:#2C3033">为一个&lt;1的项，会给原来的W[l]一个衰减的参数，所以L2范数正则化也被称为“权重衰减（Weight decay）”。</span></p><p><span style="font-size:16px;color:#2C3033">4.2 </span><span style="font-size:16px;color:#2C3033">为何正则化可以减少方差</span></p><p><span style=";color:#2C3033">过拟合状态如图所示：</span></p><p style="text-align: center;"><img src="/wp-content/uploads/image/20180206/1517847779101145.jpg" title="1517847779101145.jpg" alt="1517847779101145.jpg" width="570" height="319"/></p><p><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">便于理解的解释：</span></strong></p><p style="text-indent:28px"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">加入正则化项，可以这样理解，正则化因子</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;background:white">λ</span>在设置的足够大的情况下，为了使代价函数最小化，权重矩阵<span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;background:white"><span style="box-sizing: border-box;display: inline-block"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important">W</span></span></span></span>就会被设置为接近于0的值。那么这相当于消除了很多神经元的影响，那么图中的大的神经网络就会变成一个较小的网络。当然实际上这些神经元仍然存在，只不过是权重很小了，被我们给近似忽略而已。</p><p><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">数学解释：</span></strong></p><p><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">假设神经元中使用的激活函数为</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;background:white"><span style="box-sizing: border-box;display: inline-block"><span style="box-sizing: border-box"><span style="box-sizing: border-box;outline: 0px"><span style="box-sizing: border-box;display:inline-block"><span style="box-sizing: border-box;border-color:transparent !important;clip:rect(1.358em 1000em 2.713em -0.485em)"><span style="box-sizing: border-box"><span style="box-sizing: border-box">g</span><span style="box-sizing: border-box">(</span></span><span style="font-size: 20px">z</span><span style="box-sizing: border-box">)</span><span style="box-sizing: border-box">=</span><span style="font-size: 20px;font-family: MathJax_Main, serif">tanh</span><span style="font-size: 20px;font-family: MathJax_Main, serif"><span style="box-sizing: border-box">(</span></span><span style="font-size: 20px">z</span><span style="box-sizing: border-box;border-color:transparent !important">)</span></span></span><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"></span></span></span></span></span>，在加入正则化项后：</p><p style="text-align: center;"><img src="/wp-content/uploads/image/20180206/1517847820115058.png" title="1517847820115058.png" alt="1517847820115058.png" width="253" height="133"/></p><p style="text-indent:28px"><span style="color:#4f4f4f;font-family:微软雅黑, sans-serif"><span style="background-color: #FFFFFF;">当λ</span></span>大，导致W[l]减小，Z<span style="font-size: 14px; text-indent: 28px;">[l]=<span style="font-size: 14px; text-indent: 28px;">W[1]a[l-1]+b[l]</span></span>便会减小，由上图可知，在z较小的区域里，tanh（z）函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，从而不会发生过拟合。</p><p><span style="font-size:16px;color:#2C3033">4.3 Dropout</span><span style="font-size:16px;color:#2C3033">正则化</span></p><p><span style=";color:#2C3033">Dropout</span><span style=";color:#2C3033">的中文名称为“随机失活”，即利用一定的概率来实现上面说的那个节点不起作用。最常用的Dropout正则化算法就是Inverted Dropout正则化。其代码如下：</span></p><p><span style="font-family: Consolas;background: #F6F8FA"></span></p><pre class="brush:python;toolbar:false">keep_prob&nbsp;=&nbsp;0.8&nbsp;&nbsp;#&nbsp;设置神经元保留概率
d3&nbsp;=&nbsp;np.random.rand(a3.shape[0],&nbsp;a3.shape[1])&nbsp;&lt;&nbsp;keep_prob
#d3是一个bool量，即随机生成的数中，小于0.8设置为1，大于等于0.8设置为0。
a3&nbsp;=&nbsp;np.multiply(a3,&nbsp;d3)
#这就是将a3中需要置为零的节点置0
a3&nbsp;/=&nbsp;keep_prob
#通过对“a3&nbsp;/=&nbsp;keep_prob”,则保证无论keep_prob设置为多少，都不会对Z[4]的期望值产生影响</pre><p><span style="font-family: 宋体;background: #F6F8FA"></span><br/></p><p><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:red;background:white">注意：在测试阶段不要用dropout，因为那样会使得预测结果变得随机。</span></strong></p><p style="text-indent:28px">另外我们可以这样理解，单个神经元的工作就是接收输入，并产生一些有意义的输出，但是加入了Dropout以后，输入的特征都是有可能会被随机清除的，所以该神经元不会再特别依赖于任何一个输入特征，也就是说不会给任何一个输入设置太大的权重。所以通过传播过程，dropout将产生和L2范数相同的收缩权重的效果。</p><p style="text-indent:28px">利用这种正则化的缺点是：代价函数不能再被明确的定义，以为每次迭代都会随机消除一些神经元结点，所以我们无法绘制出每次迭代J(W,b)下降的图。</p><p>使用Dropout的步骤：</p><p>（1）关闭dropout功能，即设置 keep_prob = 1.0；</p><p>（2）运行代码，确保J(W，b)函数单调递减；</p><p>（3）再打开dropout函数</p><p><span style="font-size:16px;color:#2C3033">4.4</span> <span style="font-size:16px">其它正则化方法</span></p><p><span style=";color:#2C3033">（1）数据扩增（Data augmentation）：对图片做一些例如反转等操作，得到更多的训练集和验证集。这种方式可以很简单的或者可靠的新数据，但是价值不大。</span></p><p><span style=";color:#2C3033">（2）Early stopping：在交叉验证集的误差上升之前的点停止迭代，避免过拟合。这种方法的缺点是无法同时解决bias和variance之间的最优。</span></p><h3 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:30px;background:white"><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">第五节 归一化输入</span></h3><p><span style=";color:#2C3033">步骤：</span></p><p><span style=";color:#2C3033">（1）计算每个特征所有样本数据的均值：μ=1m∑i=1mx(i)；</span></p><p><span style=";color:#2C3033">（2）减去均值得到对称的分布：x:=x</span><span style=";font-family: &#39;微软雅黑&#39;,sans-serif;color:#2C3033">−</span><span style=";color:#2C3033">μ</span><span style=";color:#2C3033">；</span></p><p><span style=";color:#2C3033">（3）归一化方差：σ2=1m∑i=1mx(i)2，x=x/σ2</span></p><p><span style=";color:#2C3033">&nbsp;&nbsp;&nbsp; </span><span style=";color:#2C3033">归一化输入是为了防止某个参数过大，导致出现问题。</span></p><h3 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:30px;background:white"><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">第六节 梯度爆炸和梯度消失</span></h3><p style="text-align: center;"><img src="/wp-content/uploads/image/20180206/1517847950283289.png" title="1517847950283289.png" alt="1517847950283289.png" width="560" height="116"/></p><p><span style=";color:#2C3033">为了便于理解，我们做出以下假设：</span></p><p><span style=";color:#2C3033">（1）b<sup>[l]</sup>=0</span></p><p><span style=";color:#2C3033">（2）g(z)=z</span></p><p><span style=";color:#2C3033">（3）</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">W</span><sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span><span style=";font-family: &#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">L</span><span style=";font-family: &#39;MathJax_Main&#39;,serif;color:#454545;background: white">]</span></span></sup><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">=</span></span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">W</span><sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span><span style=";font-family: &#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">L</span><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">−</span><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">1</span><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></span></span></sup></span></span><span style="box-sizing: border-box">=</span><span style="font-size:20px;font-family:&#39;Cambria Math&#39;,serif;color:#454545;background:white">⋯</span><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="font-size:15px;font-family:&#39;Cambria Math&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">=</span></span><span style="font-size: 20px;font-family: MathJax_Math-italic, serif">W</span><sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></span></sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup><span style="font-family: MathJax_Main, serif">2</span></sup><sup><span style="font-family: MathJax_Main, serif">]</span></sup></span></span></span></span><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">=</span></span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">W</span><sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span><span style=";font-family: &#39;MathJax_Main&#39;,serif;color:#454545;background: white">1</span></span></span></sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style=";font-family: &#39;MathJax_Main&#39;,serif;color:#454545;background: white"></span><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></sup></span></span></span></span><span style="box-sizing: border-box;border-color:transparent !important">=W</span></p><p><span style=";color:#2C3033">所以对于目标函数输出有：</span></p><p><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">y</span><span style="box-sizing: border-box;border-color:transparent !important;clip:rect(1.412em 1000em 1.9em -0.377em)">^</span><span style="box-sizing: border-box">=</span><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">W</span></span><sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span>L<span style="font-family: MathJax_Main, serif">]</span></span></span></sup></span></span><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">W</span></span><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span><sup><span style=";font-family: &#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white">L</span></sup><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">−</span></sup><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">1</span></sup><sup><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></sup></span></span></span></span><span style="box-sizing: border-box">⋯</span><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545;background:white"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">W</span></span><sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span></span></span></sup><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"></span></span><sup><span style="font-family: MathJax_Main, serif">2</span></sup><sup><span style="font-family: MathJax_Main, serif">]</span></sup></span></span></span></span><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.412em 1000em 2.442em -0.431em)"><span style="box-sizing: border-box">W</span></span><sup><span style="box-sizing: border-box;border-color: transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span><span style=";font-family: &#39;MathJax_Main&#39;,serif;color:#454545;background: white">1</span><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#454545;background:white">]</span></span></span></sup></span></span><span style="box-sizing: border-box;border-color:transparent !important">X</span>=W<sup>n</sup>X</p><p><span style="font-size:15px;color:#454545;background:white">我们可以看出以下两点：</span></p><p><span style="font-size:15px;color:#454545;background:white">（1）假如W的各数值大于1，哪怕只大于1一点点，当n趋向于无穷的时候，W<sup>n</sup>也会趋近于无穷，由此造成梯度爆炸；</span></p><p><span style=";color:#2C3033">（2）</span><span style="font-size:15px;color:#454545;background:white">假如W的各数值小于1，哪怕只小于1一点点，当n趋向于无穷的时候，W<sup>n</sup>也会趋近于0，由此造成梯度消失。</span></p><p style="text-indent:30px"><span style="font-size:15px;color:#454545;background:white">我们可以利用初始化来缓解这个问题，但是</span><strong><span style="font-size:15px;color:red;background:white">无法</span></strong><span style="font-size: 15px;color:#454545;background:white">消除。</span></p><p><span style=";color:#2C3033">以单个神经元为例：</span></p><p style="text-align: center;"><span style=";color:#2C3033"><img src="/wp-content/uploads/image/20180206/1517847992799263.png" title="1517847992799263.png" alt="1517847992799263.png" width="327" height="126"/></span></p><p><br/></p><p><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">由上图可知，当输入的数量</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;background:white"><span style="box-sizing: border-box;display: inline-block"><span style="box-sizing: border-box"><span style="box-sizing: border-box;outline: 0px"><span style="box-sizing: border-box;display:inline-block"><span style="box-sizing: border-box;border-color:transparent !important;clip:rect(1.683em 1000em 2.442em -0.485em)"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important">n</span></span></span></span><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"></span></span></span></span></span>较大时，我们希望每个<span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;background:white"><span style="box-sizing: border-box;display: inline-block"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.683em 1000em 2.442em -0.485em)"><span style="box-sizing: border-box">w</span></span><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important">i</span></span></span></span></span></span></span></span>的值都小一些，这样它们的和得到的<span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;background:white"><span style="box-sizing: border-box;display: inline-block"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important">z</span></span></span></span>也较小。</p><p><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">我们想到可以取Wi=1/n，这被称为Xavier</span>初始化。</p><p><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">代码如下：</span></p><pre class="brush:python;toolbar:false">WL&nbsp;=&nbsp;np.random.randn(WL.shape[0],WL.shape[1])*&nbsp;np.sqrt(1/n)</pre><p><span style=";color:#2C3033"></span><br/></p><p style="text-indent:28px"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">这样的原理便是：如果激活函数的输入x</span>近似设置成均值为0，标准方差1的情况，输出z也会调整到相似的范围内。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。</p><p><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">常用的设置：</span></strong></p><p style="margin-left: 32px;background: white"><span style="font-size:13px;font-family:Symbol;color:#454545">·<span style="font-variant-numeric: normal;font-stretch: normal;font-size: 9px;line-height: normal;font-family: &#39;Times New Roman&#39;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#454545">激活函数使用RELU：</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545">Var</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545">(</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545">w</span><span style=";font-family: &#39;MathJax_Math-italic&#39;,serif;color:#454545">i</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545">)=2/</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545">n</span></p><p style="margin-left: 32px;background: white"><span style="font-size:13px;font-family:Symbol;color:#454545">·<span style="font-variant-numeric: normal;font-stretch: normal;font-size: 9px;line-height: normal;font-family: &#39;Times New Roman&#39;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#454545">激活函数使用tanh：</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545">Var</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545">(</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545">w</span><span style=";font-family: &#39;MathJax_Math-italic&#39;,serif;color:#454545">i</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#454545">)=1/</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#454545">n</span></p><p><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red">注意：</span></strong><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red;background:white">其中n是输入的神经元个数，也就是</span><span style="box-sizing: border-box;display:inline-block"><span style="box-sizing: border-box"><span style="box-sizing: border-box;outline: 0px"><span style="box-sizing: border-box;display:inline-block"><span style="box-sizing: border-box;border-color:transparent !important;clip:rect(1.249em 1000em 2.442em -0.485em)"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box;border-color:transparent !important;display:inline-block"><span style="box-sizing: border-box;clip:rect(1.683em 1000em 2.442em -0.485em)"><span style="box-sizing: border-box">n</span></span><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box"><span style="box-sizing: border-box;border-color:transparent !important"><span style="box-sizing: border-box">[</span></span>l−1]</span></span></span></span></span></span></span></span></span></span>。</strong></p><h3 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:30px;background:white"><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">第七节 梯度检验</span></h3><p><span style="font-size:16px;color:#2C3033">7.1</span> <span style="font-size:16px">单边求导VS双边求导</span></p><p style="text-align: center;"><span style=";color:#2C3033"><img src="/wp-content/uploads/image/20180206/1517848043896804.png" title="1517848043896804.png" alt="1517848043896804.png" width="670" height="303"/></span><br/></p><p><br/></p><p style="text-indent:28px"><span style=";color:#2C3033">由图我们可知，双边求导的方法更接近于实际导数，因此常用双边求导。接下来进入提督检验的整体。</span></p><p class="MsoListParagraph" style="margin-left:24px"><span style="font-size:16px;color:#2C3033">7.2<span style="font-variant-numeric: normal;font-stretch: normal;font-size: 9px;line-height: normal;font-family: &#39;Times New Roman&#39;">&nbsp; </span></span><span style="font-size:16px">梯度检验</span></p><p style="text-indent:28px"><span style=";color:#2C3033">步骤：</span></p><p><span style=";color:#2C3033">（1）连接参数</span></p><p><span style=";color:#2C3033">①将W<sup>[1]</sup>，b<sup>[1]</sup>,…, W<sup>[L]</sup>，b<sup>[L]</sup>重组为一个大的向量θ；</span></p><p><span style=";color:#2C3033">②将dW<sup>[1]</sup>，db<sup>[1]</sup>,…, dW<sup>[L]</sup>，db<sup>[L]</sup>重组为一个大的向量dθ。</span></p><p><span style=";color:#2C3033">（2）进行梯度检验</span></p><p style="text-align: center;"><img src="/wp-content/uploads/image/20180206/1517848080717658.png" title="1517848080717658.png" alt="1517848080717658.png" width="420" height="98"/><br/></p><p><span style=";color:#2C3033">判断近似相等的公式：</span></p><p style="text-align: center;"><img src="/wp-content/uploads/image/20180206/1517848200137658.jpg" title="1517848200137658.jpg" alt="1517848200137658.jpg" width="93" height="49"/></p><p><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red">注意事项：</span></strong></p><p style="margin: 8px 0 0 32px;background: white"><span style="font-size:13px;font-family:Symbol;color:red">·<span style="font-variant-numeric: normal;font-stretch: normal;font-size: 9px;line-height: normal;font-family: &#39;Times New Roman&#39;">&nbsp;</span></span><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red">不要在训练过程中使用梯度检验，只在debug的时候使用，使用完毕关闭梯度检验的功能；</span></strong></p><p style="margin-left: 32px;background: white"><span style="font-size:13px;font-family:Symbol;color:red">·<span style="font-variant-numeric: normal;font-stretch: normal;font-size: 9px;line-height: normal;font-family: &#39;Times New Roman&#39;">&nbsp;</span></span><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red">如果算法的梯度检验出现了错误，要检查每一项，找出错误，也就是说要找出哪个dθapprox[i]与dθ的值相差比较大；</span></strong></p><p style="margin: 8px 0 0 32px;background: white"><span style="font-size:13px;font-family:Symbol;color:red">·<span style="font-variant-numeric: normal;font-stretch: normal;font-size: 9px;line-height: normal;font-family: &#39;Times New Roman&#39;">&nbsp;</span></span><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red">不要忘记了正则化项；</span></strong></p><p style="margin: 8px 0 0 32px;background: white"><span style="font-size:13px;font-family:Symbol;color:red">·&nbsp;</span><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red">梯度检验不能与dropout同时使用，因为每次迭代的过程中，dropout会随机消除隐层单元的不同神经元，这时是难以计算dropout在梯度下降上的代价函数J；</span></strong></p><p style="margin: 8px 0 0 32px;background: white"><span style="font-size:13px;font-family:Symbol;color:red">·<span style="font-variant-numeric: normal;font-stretch: normal;font-size: 9px;line-height: normal;font-family: &#39;Times New Roman&#39;">&nbsp;</span></span><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red">在随机初始化的时候运行梯度检验，或许在训练几次后再进行。</span></strong></p><p style="margin: 8px 0 0 32px;background: white"><strong><span style=";font-family:&#39;微软雅黑&#39;,sans-serif;color:red"><br/></span></strong></p><p><em><strong><span style="color: #7F7F7F;">本笔记基于DEEPLEARNING.AI中Andrew Ng课程笔记整理而成，部分内容参考了http://blog.csdn.net/koala_tree/article/details/78125697内容，在此对其表示感谢~</span></strong></em></p>