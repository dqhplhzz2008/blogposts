---
ID: 3544
post_title: >
  吴恩达深度学习课程
  DeepLearning.ai
  编程作业（1-2）Part.1
post_name: '%e5%90%b4%e6%81%a9%e8%be%be%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e8%af%be%e7%a8%8b-deeplearning-ai-%e7%bc%96%e7%a8%8b%e4%bd%9c%e4%b8%9a%ef%bc%88%e7%ac%ac%e4%ba%8c%e5%91%a8%ef%bc%89'
author: 小奥
post_date: 2018-01-29 22:46:39
layout: post
link: >
  http://www.yushuai.me/2018/01/29/3544.html
published: true
tags:
  - Python
  - 深度学习
  - 神经网络
categories:
  - Deep Learning
---
<h1 style="box-sizing: border-box; margin: 8px 0px 16px; font-size: 28px; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; line-height: 36px; color: rgb(79, 79, 79); padding: 0px; white-space: normal; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box;">Part 1：Python Basics with Numpy (optional assignment)</span></h1><h2 style="box-sizing: border-box; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; line-height: 32px; color: rgb(79, 79, 79); margin: 8px 0px 16px; font-size: 24px; padding: 0px; white-space: normal; background-color: rgb(255, 255, 255);"><a style="box-sizing: border-box; background: transparent; color: rgb(78, 161, 219); margin: 0px; padding: 0px; font-weight: 400; outline: 0px;"></a>1 - Building basic functions with numpy</h2><p style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; padding: 0px; font-size: 16px; color: rgb(79, 79, 79); line-height: 26px; text-align: justify; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; white-space: normal; background-color: rgb(255, 255, 255);">Numpy is the main package for scientific computing in Python. It is maintained by a large community (www.numpy.org). In this exercise you will learn several key numpy functions such as np.exp, np.log, and np.reshape. You will need to know how to use these functions for future assignments.</p><h3 style="box-sizing: border-box; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; line-height: 30px; color: rgb(79, 79, 79); margin: 8px 0px 16px; font-size: 22px; padding: 0px; white-space: normal; background-color: rgb(255, 255, 255);"><a style="box-sizing: border-box; background: transparent; color: rgb(78, 161, 219); margin: 0px; padding: 0px; font-weight: 400; outline: 0px;"></a>1.1 - sigmoid function, np.exp()</h3><p style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; padding: 0px; font-size: 16px; color: rgb(79, 79, 79); line-height: 26px; text-align: justify; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; white-space: normal; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; font-weight: 700;">Exercise</span>: Build a function that returns the sigmoid of a real number x. <span style="color: #4F4F4F; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; text-align: justify; background-color: #FFFFFF;">using numpy.</span></p><p style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; padding: 0px; font-size: 16px; color: rgb(79, 79, 79); line-height: 26px; text-align: justify; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; white-space: normal; background-color: rgb(255, 255, 255);"><br/></p><pre class="brush:python;toolbar:false">import&nbsp;numpy&nbsp;as&nbsp;np
def&nbsp;sigmoid(x):
&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;define&nbsp;a&nbsp;sigmoid&nbsp;function
&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;is&nbsp;input:&nbsp;An&nbsp;array
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;function&nbsp;is&nbsp;to&nbsp;compute&nbsp;the&nbsp;sigmoid&nbsp;function&nbsp;value
&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;s&nbsp;=&nbsp;1.0&nbsp;/&nbsp;(1&nbsp;+&nbsp;(1/np.exp(x)))
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;s&nbsp;#return&nbsp;the&nbsp;sigmoid&nbsp;function&nbsp;value
#main&nbsp;function&nbsp;
m&nbsp;=&nbsp;np.array([1,2,3])
print(sigmoid(m))</pre><h3 style="box-sizing: border-box; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; line-height: 30px; color: rgb(79, 79, 79); margin: 8px 0px 16px; font-size: 22px; padding: 0px; white-space: normal; background-color: rgb(255, 255, 255);">1.2 - Sigmoid gradient</h3><p style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; padding: 0px; font-size: 16px; color: rgb(79, 79, 79); line-height: 26px; text-align: justify; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; white-space: normal; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; font-weight: 700;">Exercise</span>: Implement the function sigmoid_grad() to compute the gradient of the sigmoid function with respect to its input x.&nbsp;</p><p style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; padding: 0px; font-size: 16px; color: rgb(79, 79, 79); line-height: 26px; text-align: justify; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; white-space: normal; background-color: rgb(255, 255, 255);"><span style="color: #454545; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; background-color: #FFFFFF;">You often code this function in two steps:&nbsp;</span><br/><span style="color: #454545; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; background-color: #FFFFFF;">1. Set s to be the sigmoid of x. You might find your sigmoid(x) function useful.&nbsp;</span><br/><span style="color: #454545; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; background-color: #FFFFFF;">2. Compute&nbsp;σ′(x)=s(1−s)</span></p><pre class="brush:python;toolbar:false">import&nbsp;numpy&nbsp;as&nbsp;np
def&nbsp;sigmoid_derivative(x):
&nbsp;&nbsp;&nbsp;&nbsp;s&nbsp;=&nbsp;1.0&nbsp;/&nbsp;(1&nbsp;+&nbsp;1&nbsp;/&nbsp;np.exp(x))
&nbsp;&nbsp;&nbsp;&nbsp;ds&nbsp;=&nbsp;s&nbsp;*&nbsp;(1-s)
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;ds
x&nbsp;=&nbsp;np.array([1,&nbsp;2,&nbsp;3])
print&nbsp;(&quot;sigmoid_derivative(x)&nbsp;=&nbsp;&quot;&nbsp;+&nbsp;str(sigmoid_derivative(x)))</pre><p style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; padding: 0px; font-size: 16px; color: rgb(79, 79, 79); line-height: 26px; text-align: justify; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; white-space: normal; background-color: rgb(255, 255, 255);"><span style="color: #454545; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; background-color: #FFFFFF;"><br/></span></p><h3 style="box-sizing: border-box; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; line-height: 30px; color: rgb(79, 79, 79); margin: 8px 0px 16px; font-size: 22px; padding: 0px; white-space: normal; background-color: rgb(255, 255, 255);">1.3 - Reshaping arrays</h3><p style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; padding: 0px; font-size: 16px; color: rgb(79, 79, 79); line-height: 26px; text-align: justify; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; white-space: normal; background-color: rgb(255, 255, 255);">Two common numpy functions used in deep learning are&nbsp;<em>np.shape</em>&nbsp;and&nbsp;<em>np.reshape()</em>.&nbsp;<br/>- X.shape is used to get the shape (dimension) of a matrix/vector X.&nbsp;<br/>- X.reshape(…) is used to reshape X into some other dimension.</p><p style="box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; padding: 0px; font-size: 16px; color: rgb(79, 79, 79); line-height: 26px; text-align: justify; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; white-space: normal; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; font-weight: 700; color: #4F4F4F; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; text-align: justify; background-color: #FFFFFF;">Exercise</span><span style="color: #4F4F4F; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; text-align: justify; background-color: #FFFFFF;">: Implement&nbsp;</span><code style="box-sizing: border-box; font-family: Consolas, Inconsolata, Courier, monospace; font-size: 14px; padding: 2px 4px; color: rgb(199, 37, 78); background-color: rgb(249, 242, 244); border-radius: 4px; line-height: 22px; text-align: justify;">image2vector()</code><span style="color: #4F4F4F; font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, SimHei, Arial, SimSun; text-align: justify; background-color: #FFFFFF;">&nbsp;that takes an input of shape (length, height, 3) and returns a vector of shape (length*height*3, 1). For example, if you would like to reshape an array v of shape (a, b, c) into a vector of shape (a*b,c) you would do:</span></p><pre class="brush:python;toolbar:false">v&nbsp;=&nbsp;v.reshape((v.shape[0]*v.shape[1],&nbsp;v.shape[2]))&nbsp;#&nbsp;v.shape[0]=a;v.shape[1]=b;v.shape[2]=c</pre><ul style="list-style-type: none;" class=" list-paddingleft-2"><li><p>Please don’t hardcode the dimensions of image as a constant. Instead look up the quantities you need with&nbsp;<code style="box-sizing: border-box; font-family: Consolas, Inconsolata, Courier, monospace; font-size: 14px; padding: 2px 4px; color: rgb(199, 37, 78); white-space: nowrap; background-color: rgb(249, 242, 244); border-radius: 4px; line-height: 22px;">image.shape[0]</code>, etc.</p></li></ul><pre class="brush:python;toolbar:false">#Reshaping&nbsp;arrays
def&nbsp;image2vector(imag):
&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;takes&nbsp;an&nbsp;input&nbsp;of&nbsp;shape&nbsp;(length,height,3)and&nbsp;returns&nbsp;a&nbsp;vector&nbsp;of&nbsp;shape(length*height*3,1)
&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;v&nbsp;=&nbsp;img.reshape((img.shape[0]*img.shape[1]*img.shape[2],1&nbsp;))
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;v
img&nbsp;=&nbsp;np.array([[[&nbsp;0.67826139,&nbsp;&nbsp;0.29380381],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;0.90714982,&nbsp;&nbsp;0.52835647],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;0.4215251&nbsp;,&nbsp;&nbsp;0.45017551]],
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[[&nbsp;0.92814219,&nbsp;&nbsp;0.96677647],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;0.85304703,&nbsp;&nbsp;0.52351845],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;0.19981397,&nbsp;&nbsp;0.27417313]],
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[[&nbsp;0.60659855,&nbsp;&nbsp;0.00533165],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;0.10820313,&nbsp;&nbsp;0.49978937],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;0.34144279,&nbsp;&nbsp;0.94630077]]])
m&nbsp;=&nbsp;image2vector(img)
&nbsp;
print&nbsp;(&quot;image2vector(image)&nbsp;=&nbsp;&quot;&nbsp;+&nbsp;str(m))</pre><p>&nbsp;</p><p style="margin: 8px 0 16px;line-height: 30px;background: white"><strong><span style="font-size:22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">1.4 - Normalizing rows</span></strong></p><p style="line-height:26px;background:white"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Another common technique we use in Machine Learning and Deep Learning is to normalize our data. It often leads to a better performance because gradient descent converges faster after normalization. Here, by normalization we mean changing x to&nbsp;</span><span style=";font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0">x</span><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0">∥</span><span style=";font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0">x</span><span style=";font-family:&#39;MathJax_Main&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0">∥</span><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;(dividing each row vector of x by its norm).</span></p><p style="line-height:26px;background:white"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"></span></p><pre class="brush:python;toolbar:false">#&nbsp;GRADED&nbsp;FUNCTION:&nbsp;normalizeRows
def&nbsp;normalizeRows(x):
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x_norm&nbsp;=&nbsp;np.linalg.norm(x,axis=1,keepdims=True)#x代表对x求解，ord后面的数字
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#表示是几范数，无穷范数是np.inf，axis=1代表1维数据，keepdims表示如果将其设置
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#为true，则将赋范的轴作为尺寸为1的尺寸保留在结果中。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;x&nbsp;/&nbsp;x_norm
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;x
&nbsp;
x&nbsp;=&nbsp;np.array([[0,&nbsp;3,&nbsp;4],[1,&nbsp;6,&nbsp;4]])
print(&quot;normalizeRows(x)&nbsp;=&nbsp;&quot;&nbsp;+&nbsp;str(normalizeRows(x)))</pre><p style="line-height:26px;background:white"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"></span><br/></p><p style="line-height:26px;background:white"><strong><span style="font-family: 微软雅黑, sans-serif;color: blue">What you need to remember:</span></strong><span style="font-family: 微软雅黑, sans-serif;color: blue">&nbsp;</span><span style="font-family: &#39;微软雅黑&#39;,sans-serif;color:blue"><br/> - np.exp(x) works for any np.array x and applies the exponential function to every coordinate&nbsp;<br/> - the sigmoid function and its gradient&nbsp;<br/> - image2vector is commonly used in deep learning&nbsp;<br/> - np.reshape is widely used. In the future, you’ll see that keeping your matrix/vector dimensions straight will go toward eliminating a lot of bugs.&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:blue"><br/> - numpy has efficient built-in functions&nbsp;<br/> - broadcasting is extremely useful</span></p><p style="line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:blue"></span></p><h2 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:32px;background:white"><span style="font-family: &#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">2) Vectorization</span></h2><p style="margin: 0 0 16px;text-align: justify;line-height: 26px;background: white;box-sizing: border-box"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">In deep learning, you deal with very large datasets. Hence, a non-computationally-optimal function can become a huge bottleneck in your algorithm and can result in a model that takes ages to run. To make sure that your code is computationally efficient, you will use vectorization.&nbsp;</span></p><p><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">Note</span></strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">that&nbsp;</span><code style="box-sizing: border-box;border-radius: 4px"><span style="font-size:16px;font-family:Consolas;color:#C7254E;background:#F9F2F4">np.dot()</span></code><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">performs a matrix-matrix or matrix-vector multiplication. This is different from&nbsp;</span><code style="box-sizing: border-box;border-radius: 4px"><span style="font-size:16px;font-family:Consolas;color:#C7254E;background:#F9F2F4">np.multiply()</span></code><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">and the&nbsp;</span><code style="box-sizing: border-box;border-radius: 4px"><span style="font-size:16px;font-family:Consolas;color:#C7254E;background:#F9F2F4">*</span></code><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">operator (which is equivalent to&nbsp;</span><code style="box-sizing: border-box;border-radius: 4px"><span style="font-size:16px;font-family:Consolas;color:#C7254E;background:#F9F2F4">.*</span></code><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">in Matlab/Octave), which performs an element-wise multiplication.</span></p><h3 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:30px;background:white"><span style="font-size: 22px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">2.1 Implement the L1 and L2 loss functions</span></h3><p style="margin: 0 0 16px;text-align: justify;line-height: 26px;background: white;box-sizing: border-box"><strong style="box-sizing: border-box"><span style="font-family: &#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Exercise</span></strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">: Implement the numpy vectorized version of the L1 loss. You may find the function abs(x) (absolute value of x) useful.</span></p><p style=";text-align: justify;line-height: 26px;background: white;box-sizing: border-box"><strong style="box-sizing: border-box"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Reminder</span></strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">:&nbsp;<br/> - The loss is used to evaluate the performance of your model. The bigger your loss is, the more different your predictions (</span><span style="box-sizing: border-box;transition: none;display:inline-block"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0"><span style="box-sizing: border-box;transition: none;display:inline-block"><span style="box-sizing: border-box;word-wrap: normal;max-width:none;max-height: none;min-width: 0px;min-height: 0px;float:none;word-spacing:normal"><span style="box-sizing: border-box;transition: none;border-style:initial;border-color:transparent !important;border-image: initial;clip:rect(1.403em 1000em 2.652em -0.447em)"><span style="box-sizing: border-box;transition: none">y</span></span></span></span></span></span>) are from the true values (<span style="box-sizing: border-box;transition: none;display:inline-block"><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0"><span style="box-sizing: border-box;transition: none;display:inline-block"><span style="box-sizing: border-box;word-wrap: normal;max-width:none;max-height: none;min-width: 0px;min-height: 0px;float:none;word-spacing:normal"><span style="box-sizing: border-box;transition: none;border-style:initial;border-color:transparent !important;border-image: initial;clip:rect(1.952em 1000em 2.902em -0.447em)"><span style="box-sizing: border-box;transition: none;border-style:initial;border-color:transparent !important;border-image: initial">y</span></span></span></span></span></span>). In deep learning, you use optimization algorithms like Gradient Descent to train your model and to minimize the cost.&nbsp;</p><pre class="brush:python;toolbar:false">#&nbsp;GRADED&nbsp;FUNCTION:&nbsp;L1
import&nbsp;numpy&nbsp;as&nbsp;np
def&nbsp;L1(yhat,&nbsp;y):
&nbsp;&nbsp;&nbsp;&nbsp;loss&nbsp;=&nbsp;np.sum(np.abs(&nbsp;y&nbsp;-&nbsp;yhat))
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;loss
&nbsp;
yhat&nbsp;=&nbsp;np.array([.9,&nbsp;0.2,&nbsp;0.1,&nbsp;.4,&nbsp;.9])
y&nbsp;=&nbsp;np.array([1,&nbsp;0,&nbsp;0,&nbsp;1,&nbsp;1])
print(&quot;L1&nbsp;=&nbsp;&quot;&nbsp;+&nbsp;str(L1(yhat,y)))</pre><p><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">Exercise</span></strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">: Implement the numpy vectorized version of the L2 loss. There are several way of implementing the L2 loss but you may find the function np.dot() useful. As a reminder, if&nbsp;</span><span style="font-size:20px;font-family:&#39;MathJax_Math-italic&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0;background:white"><span style="box-sizing: border-box;transition: none;display:inline-block"><span style="box-sizing: border-box"><span style="box-sizing: border-box;word-wrap: normal;max-width: none;max-height: none;min-width: 0px;min-height: 0px;float: none"><span style="box-sizing: border-box;transition: none;display:inline-block"><span style="box-sizing: border-box;transition: none;border-style:initial;border-color:transparent !important;border-image: initial;clip:rect(1.802em 1000em 3.103em -0.398em)"><span style="box-sizing: border-box;transition: none"><span style="box-sizing: border-box;transition: none">x</span></span><span style="font-size: 20px;font-family: MathJax_Main, serif;border: 1px none windowtext;padding: 0">=</span><span style="box-sizing: border-box;transition: none">[</span><span style="box-sizing: border-box;transition: none;display:inline-block;border-style:initial;border-color:transparent !important;border-image: initial"><span style="font-size: 20px;border: 1px none windowtext;padding: 0"><span style="box-sizing: border-box;transition: none;clip:rect(1.952em 1000em 2.702em -0.398em)"><span style="box-sizing: border-box;transition: none">x</span></span><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial"><span style="box-sizing: border-box;transition: none">1</span></span></span></span><span style="box-sizing: border-box;transition: none">,</span><span style="box-sizing: border-box;transition: none;display:inline-block;border-style: initial;border-color:transparent !important;border-image: initial"><span style="font-size: 20px;border: 1px none windowtext;padding: 0"><span style="box-sizing: border-box;transition: none;clip:rect(1.952em 1000em 2.702em -0.398em)"><span style="box-sizing: border-box;transition: none">x</span></span><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial"><span style="box-sizing: border-box;transition: none">2</span></span></span></span><span style="box-sizing: border-box;transition: none">,</span><span style="box-sizing: border-box;transition: none">.</span><span style="box-sizing: border-box;transition: none">.</span><span style="box-sizing: border-box;transition: none">.</span><span style="box-sizing: border-box;transition: none">,</span><span style="box-sizing: border-box;transition: none;display:inline-block;border-style: initial;border-color:transparent !important;border-image: initial"><span style="font-size: 20px;border: 1px none windowtext;padding: 0"><span style="box-sizing: border-box;transition: none;clip:rect(1.952em 1000em 2.702em -0.398em)"><span style="box-sizing: border-box;transition: none">x</span></span><span style="box-sizing: border-box;transition: none;border-style:initial;border-color:transparent !important;border-image: initial"><span style="box-sizing: border-box;transition: none">n</span></span></span></span><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial">]</span></span></span><span style="box-sizing: border-box;transition: none;display:inline-block;border-style: initial;border-color:transparent !important;border-image: initial"></span></span></span></span></span>, then&nbsp;<code style="box-sizing: border-box;border-radius: 4px"><span style="font-size:16px;font-family:Consolas;color:#C7254E;background:#F9F2F4">np.dot(x,x)</span></code><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F;background:white">=&nbsp;</span><span style="font-size:20px;font-family:&#39;MathJax_Size1&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0;background:white"><span style="box-sizing: border-box;transition: none;display:inline-block"><span style="box-sizing: border-box"><span style="box-sizing: border-box;word-wrap: normal;max-width: none;max-height: none;min-width: 0px;min-height: 0px;float: none"><span style="box-sizing: border-box;transition: none;display:inline-block"><span style="box-sizing: border-box;transition: none;border-style:initial;border-color:transparent !important;border-image: initial;clip:rect(1.353em 1000em 2.902em -0.398em)"><span style="box-sizing: border-box;transition: none"><span style="box-sizing: border-box;transition: none"><span style="box-sizing: border-box;transition: none;display:inline-block;border-style: initial;border-color:transparent !important;border-image: initial"><span style="box-sizing: border-box;transition: none;clip:rect(1.852em 1000em 3.152em -0.398em)"><span style="box-sizing: border-box;transition: none;vertical-align:.003em">∑</span></span><span style="box-sizing: border-box;transition: none;clip:rect(1.952em 1000em 2.552em -0.447em)"><span style="box-sizing: border-box;transition: none">n</span></span><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial;clip:rect(1.852em 1000em 2.752em -0.447em)"><span style="box-sizing: border-box;transition: none"><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial"><span style="box-sizing: border-box;transition: none">j</span></span><span style="font-family: MathJax_Main, serif;border: 1px none windowtext;padding: 0">=</span><span style="font-family: MathJax_Main, serif;border: 1px none windowtext;padding: 0">0</span></span></span></span></span><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial"><span style="box-sizing: border-box;transition: none;display:inline-block;border-style: initial;border-color:transparent !important;border-image: initial"><span style="box-sizing: border-box;transition: none;clip:rect(1.952em 1000em 2.702em -0.398em)"><span style="box-sizing: border-box;transition: none">x</span></span><span style="box-sizing: border-box;transition: none;clip:rect(1.852em 1000em 2.603em -0.398em)"><span style="box-sizing: border-box;transition: none"><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial"><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial">2</span></span></span></span></span><span style="box-sizing: border-box;transition: none;border-style:initial;border-color: transparent !important;border-image: initial;clip:rect(1.802em 1000em 2.702em -0.447em)"><span style="box-sizing: border-box;transition: none">j</span></span></span></span></span></span></span></span></span></span>.</p><pre class="brush:python;toolbar:false">#GRADED&nbsp;FUNCTION:&nbsp;L2
def&nbsp;L2(yhat,y):
&nbsp;&nbsp;&nbsp;&nbsp;#loss=np.sum(np.power((y-yhat),2))
&nbsp;&nbsp;&nbsp;&nbsp;loss=&nbsp;np.sum(np.dot(y-yhat,y-yhat))
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;loss
&nbsp;
yhat&nbsp;=&nbsp;np.array([.9,&nbsp;0.2,&nbsp;0.1,&nbsp;.4,&nbsp;.9])
y&nbsp;=&nbsp;np.array([1,&nbsp;0,&nbsp;0,&nbsp;1,&nbsp;1])
print(&quot;L2&nbsp;=&nbsp;&quot;&nbsp;+&nbsp;str(L2(yhat,y)))</pre><p><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:blue;background:white">What to remember:</span></strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:blue;background:white">&nbsp;</span><span style="font-family: &#39;微软雅黑&#39;,sans-serif;color:blue"><br/> <span style="background:white">- Vectorization is very important in deep learning. It provides computational efficiency and clarity.&nbsp;</span><br/> <span style="background:white">- You have reviewed the L1 and L2 loss.&nbsp;</span><br/> <span style="background:white">- You are familiar with many numpy functions such as np.sum, np.dot, np.multiply, np.maximum, etc</span><span style="background: white">…</span></span></p><p><span style="font-family: &#39;微软雅黑&#39;,sans-serif;color:blue"><span style="background: white"></span></span></p><p style="margin: 8px 0 16px;line-height: 36px;background: white"><strong><span style="font-size:28px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Part 2</span></strong><strong><span style="font-size:28px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">： Logistic Regression with a Neural Network mindset</span></strong></p><p style="margin-bottom:16px;line-height:26px;background:white"><strong><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">You will learn to:</span></strong><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;<br/> - Build the general architecture of a learning algorithm, including:&nbsp;<br/> - Initializing parameters&nbsp;<br/> - Calculating the cost function and its gradient&nbsp;<br/> - Using an optimization algorithm (gradient descent)&nbsp;<br/> - Gather all three functions above into a main model function, in the right order.</span></p><p style="line-height: 32px;background: white"><a></a><strong><span style="font-size:24px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">1 - Packages</span></strong></p><p style="line-height:26px;background:white"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">First, let</span><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">’s run the cell below to import all the packages that you will need during this assignment.&nbsp;<br/> -&nbsp;<a href="http://www.numpy.org/" target="_blank"><span style="color:#6795B5">numpy</span></a>&nbsp;is the fundamental package for scientific computing with Python.&nbsp;<br/> -&nbsp;</span><a href="http://www.h5py.org/" target="_blank"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#6795B5">h5py</span></a><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;is a common package to interact with a dataset that is stored on an H5 file.&nbsp;<br/> -&nbsp;<a href="http://matplotlib.org/" target="_blank"><span style="color: #6795B5">matplotlib</span></a>&nbsp;is a famous library to plot graphs in Python.&nbsp;<br/> -&nbsp;</span><a href="http://www.pythonware.com/products/pil/" target="_blank"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#6795B5">PIL</span></a><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;and&nbsp;<a href="https://www.scipy.org/" target="_blank"><span style="color:#6795B5">scipy</span></a>&nbsp;are used here to test your model with your own picture at the end.</span></p><h2 style="margin-top:8px;margin-right:0;margin-bottom:16px;margin-left: 0;line-height:32px;background:white"><span style="font-family: &#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">2 - Overview of the Problem set</span></h2><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Problem Statement</span></strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">: You are given a dataset (</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">“data.h5”) containing:&nbsp;<br/> - a training set of m_train images labeled as cat (y=1) or non-cat (y=0)&nbsp;<br/> - a test set of m_test images labeled as cat or non-cat&nbsp;<br/> - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px).</span></p><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat.</span></p><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Let</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">’s get more familiar with the dataset. Load the data by running the following code.</span></p><p>train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()</p><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">We added </span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">“_orig” at the end of image datasets (train and test) because we are going to preprocess them. After preprocessing, we will end up with train_set_x and test_set_x (the labels train_set_y and test_set_y don’t need any preprocessing).</span></p><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Each line of your train_set_x_orig and test_set_x_orig is an array representing an image. You can visualize an example by running the following code. Feel free also to change the&nbsp;</span><code><span style="font-size:14px;font-family:Consolas;color:#C7254E;background:#F9F2F4">index</span></code><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">value and re-run to see other images.</span></p><p># Example of a picture</p><pre class="brush:python;toolbar:false">index&nbsp;=&nbsp;19
plt.imshow(train_set_x_orig[index])
print(&quot;y=&quot;+str(train_set_y[:,index])+&quot;,&quot;+classes[np.squeeze(train_set_y[:,index])].decode(&quot;utf-8&quot;)+&quot;&#39;picture.&quot;)</pre><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Many software bugs in deep learning come from having matrix/vector dimensions that don</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">’t fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs.</span></p><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Exercise:</span></strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Find the values for:&nbsp;<br/> - m_train (number of training examples)&nbsp;<br/> - m_test (number of test examples)&nbsp;<br/> - num_px (= height = width of a training image)&nbsp;<br/> Remember that&nbsp;</span><code><span style="font-size:14px;font-family:Consolas;color:#C7254E;background:#F9F2F4">train_set_x_orig</span></code><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access&nbsp;</span><code><span style="font-size:14px;font-family:Consolas;color:#C7254E;background:#F9F2F4">m_train</span></code><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">by writing&nbsp;</span><code><span style="font-size:14px;font-family:Consolas;color:#C7254E;background:#F9F2F4">train_set_x_orig.shape[0]</span></code></p><p style="line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"></span></p><pre class="brush:python;toolbar:false">#access&nbsp;m_train,m_test,num_px
m_train&nbsp;=&nbsp;train_set_x_orig.shape[0]
m_test&nbsp;=&nbsp;test_set_x_orig.shape[0]
num_px&nbsp;=&nbsp;train_set_x_orig.shape[1]
&nbsp;
print&nbsp;(&quot;Number&nbsp;of&nbsp;training&nbsp;examples:&nbsp;m_train&nbsp;=&nbsp;&quot;&nbsp;+&nbsp;str(m_train))
print&nbsp;(&quot;Number&nbsp;of&nbsp;testing&nbsp;examples:&nbsp;m_test&nbsp;=&nbsp;&quot;&nbsp;+&nbsp;str(m_test))
print&nbsp;(&quot;Height/Width&nbsp;of&nbsp;each&nbsp;image:&nbsp;num_px&nbsp;=&nbsp;&quot;&nbsp;+&nbsp;str(num_px))
print&nbsp;(&quot;Each&nbsp;image&nbsp;is&nbsp;of&nbsp;size:&nbsp;(&quot;&nbsp;+&nbsp;str(num_px)&nbsp;+&nbsp;&quot;,&nbsp;&quot;&nbsp;+&nbsp;str(num_px)&nbsp;+&nbsp;&quot;,&nbsp;3)&quot;)
print&nbsp;(&quot;train_set_x&nbsp;shape:&nbsp;&quot;&nbsp;+&nbsp;str(train_set_x_orig.shape))
print&nbsp;(&quot;train_set_y&nbsp;shape:&nbsp;&quot;&nbsp;+&nbsp;str(train_set_y.shape))
print&nbsp;(&quot;test_set_x&nbsp;shape:&nbsp;&quot;&nbsp;+&nbsp;str(test_set_x_orig.shape))
print&nbsp;(&quot;test_set_y&nbsp;shape:&nbsp;&quot;&nbsp;+&nbsp;str(test_set_y.shape))</pre><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"></span><br/></p><p style=";margin-bottom:0;text-align:justify;text-justify: inter-ideograph;line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">For convenience, you should now reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px&nbsp;</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0">∗</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">num_px&nbsp;</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0">∗</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.</span></p><p style=";margin-bottom:0;text-align:justify;text-justify: inter-ideograph;line-height:26px;background:white"><strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Exercise:</span></strong><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px&nbsp;</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0">∗</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">num_px&nbsp;</span><span style="font-size:20px;font-family:&#39;MathJax_Main&#39;,serif;color:#4F4F4F;border:none windowtext 1px;padding:0">∗</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">&nbsp;</span><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">3, 1).</span></p><p style="line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"></span></p><pre class="brush:python;toolbar:false">#reshape&nbsp;the&nbsp;training&nbsp;and&nbsp;test&nbsp;examples
train_set_x_flatten&nbsp;=&nbsp;train_set_x_orig.reshape(m_train,&nbsp;-1).T
test_set_x_flatten&nbsp;=&nbsp;test_set_x_orig.reshape(m_test,&nbsp;-1).T
print(&quot;====================分割线======================&quot;)
print&nbsp;(&quot;train_set_x_flatten&nbsp;shape:&nbsp;&quot;&nbsp;+&nbsp;str(train_set_x_flatten.shape))
print&nbsp;(&quot;train_set_y&nbsp;shape:&nbsp;&quot;&nbsp;+&nbsp;str(train_set_y.shape))
print&nbsp;(&quot;test_set_x_flatten&nbsp;shape:&nbsp;&quot;&nbsp;+&nbsp;str(test_set_x_flatten.shape))
print&nbsp;(&quot;test_set_y&nbsp;shape:&nbsp;&quot;&nbsp;+&nbsp;str(test_set_y.shape))
print&nbsp;(&quot;sanity&nbsp;check&nbsp;after&nbsp;reshaping:&nbsp;&quot;&nbsp;+&nbsp;str(train_set_x_flatten[0:5,0]))
train_set_x&nbsp;=&nbsp;train_set_x_flatten/255
test_set_x&nbsp;=&nbsp;test_set_x_flatten/255</pre><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><span style="font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F"></span><br/></p><p style="margin-bottom:16px;line-height:26px;background:white"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.</span></p><p style="margin-bottom:16px;line-height:26px;background:white"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).</span></p><p style="margin-bottom:16px;line-height:26px;background:white"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Let</span><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">’s standardize our dataset.</span></p><p><span style="font-family: Consolas;background: #F6F8FA"></span></p><pre class="brush:python;toolbar:false">train_set_x&nbsp;=&nbsp;train_set_x_flatten/255.
test_set_x&nbsp;=&nbsp;test_set_x_flatten/255.</pre><p style="margin-top:0;margin-right:0;margin-bottom:16px;margin-left: 0;text-align:justify;text-justify:inter-ideograph;line-height:26px;background:white"><span style="font-size:14px;font-family:Consolas;color:#006666"></span><br/></p><p style="margin-bottom:16px;line-height:26px;background:white"><strong><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:blue">What you need to remember:</span></strong></p><p style="margin-bottom:16px;line-height:26px;background:white"><span style="font-size:16px;font-family:&#39;微软雅黑&#39;,sans-serif;color:#4F4F4F">Common steps for pre-processing a new dataset are:&nbsp;<br/> </span><span style="color: #FF0000;"><strong><span style="font-size: 16px; font-family: 微软雅黑, sans-serif;">- Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, …)&nbsp;<br/> - Reshape the datasets such that each example is now a vector of size (num_px * num_px * 3, 1)&nbsp;<br/> - “Standardize” the data</span></strong></span></p><p>未完待续</p>